{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f17d903",
   "metadata": {},
   "source": [
    "# Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6281368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openvino==2025.2.0 (from -r requirements.txt (line 1))\n",
      "  Using cached openvino-2025.2.0-19140-cp312-cp312-manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting numpy==2.2.6 (from -r requirements.txt (line 2))\n",
      "  Using cached numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting opencv-python==4.11.0.86 (from -r requirements.txt (line 3))\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting pillow==11.3.0 (from -r requirements.txt (line 4))\n",
      "  Using cached pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting transformers==4.52.4 (from -r requirements.txt (line 5))\n",
      "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting torch==2.7.1 (from -r requirements.txt (line 6))\n",
      "  Downloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Collecting torchvision==0.22.1 (from -r requirements.txt (line 7))\n",
      "  Downloading torchvision-0.22.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting protobuf==5.28.2 (from -r requirements.txt (line 8))\n",
      "  Downloading protobuf-5.28.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting sentencepiece==0.2.0 (from -r requirements.txt (line 9))\n",
      "  Using cached sentencepiece-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting optimum-intel==1.24.0 (from -r requirements.txt (line 10))\n",
      "  Downloading optimum_intel-1.24.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting huggingface_hub (from -r requirements.txt (line 11))\n",
      "  Downloading huggingface_hub-0.34.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting nncf (from -r requirements.txt (line 12))\n",
      "  Using cached nncf-2.17.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting av (from -r requirements.txt (line 13))\n",
      "  Downloading av-15.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
      "Collecting openvino-telemetry>=2023.2.1 (from openvino==2025.2.0->-r requirements.txt (line 1))\n",
      "  Using cached openvino_telemetry-2025.2.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: packaging in /home/eze/openvino/.venv/lib/python3.12/site-packages (from openvino==2025.2.0->-r requirements.txt (line 1)) (25.0)\n",
      "Collecting filelock (from transformers==4.52.4->-r requirements.txt (line 5))\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting pyyaml>=5.1 (from transformers==4.52.4->-r requirements.txt (line 5))\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.52.4->-r requirements.txt (line 5))\n",
      "  Using cached regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting requests (from transformers==4.52.4->-r requirements.txt (line 5))\n",
      "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers==4.52.4->-r requirements.txt (line 5))\n",
      "  Using cached tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers==4.52.4->-r requirements.txt (line 5))\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers==4.52.4->-r requirements.txt (line 5))\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions>=4.10.0 (from torch==2.7.1->-r requirements.txt (line 6))\n",
      "  Using cached typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting setuptools (from torch==2.7.1->-r requirements.txt (line 6))\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting sympy>=1.13.3 (from torch==2.7.1->-r requirements.txt (line 6))\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch==2.7.1->-r requirements.txt (line 6))\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch==2.7.1->-r requirements.txt (line 6))\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch==2.7.1->-r requirements.txt (line 6))\n",
      "  Using cached fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch==2.7.1->-r requirements.txt (line 6))\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch==2.7.1->-r requirements.txt (line 6))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch==2.7.1->-r requirements.txt (line 6))\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch==2.7.1->-r requirements.txt (line 6))\n",
      "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch==2.7.1->-r requirements.txt (line 6))\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch==2.7.1->-r requirements.txt (line 6))\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch==2.7.1->-r requirements.txt (line 6))\n",
      "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch==2.7.1->-r requirements.txt (line 6))\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch==2.7.1->-r requirements.txt (line 6))\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch==2.7.1->-r requirements.txt (line 6))\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch==2.7.1->-r requirements.txt (line 6))\n",
      "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch==2.7.1->-r requirements.txt (line 6))\n",
      "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch==2.7.1->-r requirements.txt (line 6))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch==2.7.1->-r requirements.txt (line 6))\n",
      "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.1 (from torch==2.7.1->-r requirements.txt (line 6))\n",
      "  Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting optimum==1.26.* (from optimum-intel==1.24.0->-r requirements.txt (line 10))\n",
      "  Downloading optimum-1.26.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting datasets>=1.4.0 (from optimum-intel==1.24.0->-r requirements.txt (line 10))\n",
      "  Using cached datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting scipy (from optimum-intel==1.24.0->-r requirements.txt (line 10))\n",
      "  Using cached scipy-1.16.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (61 kB)\n",
      "Collecting onnx (from optimum-intel==1.24.0->-r requirements.txt (line 10))\n",
      "  Using cached onnx-1.18.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface_hub->-r requirements.txt (line 11))\n",
      "  Using cached hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Collecting jsonschema>=3.2.0 (from nncf->-r requirements.txt (line 12))\n",
      "  Using cached jsonschema-4.25.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting natsort>=7.1.0 (from nncf->-r requirements.txt (line 12))\n",
      "  Using cached natsort-8.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting networkx (from torch==2.7.1->-r requirements.txt (line 6))\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting ninja<1.12,>=1.10.0.post2 (from nncf->-r requirements.txt (line 12))\n",
      "  Using cached ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting pandas<2.3,>=1.1.5 (from nncf->-r requirements.txt (line 12))\n",
      "  Using cached pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: psutil in /home/eze/openvino/.venv/lib/python3.12/site-packages (from nncf->-r requirements.txt (line 12)) (7.0.0)\n",
      "Collecting pydot<=3.0.4,>=1.4.1 (from nncf->-r requirements.txt (line 12))\n",
      "  Using cached pydot-3.0.4-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pymoo>=0.6.0.1 (from nncf->-r requirements.txt (line 12))\n",
      "  Using cached pymoo-0.6.1.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting rich>=13.5.2 (from nncf->-r requirements.txt (line 12))\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting scikit-learn>=0.24.0 (from nncf->-r requirements.txt (line 12))\n",
      "  Using cached scikit_learn-1.7.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting tabulate>=0.9.0 (from nncf->-r requirements.txt (line 12))\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/eze/openvino/.venv/lib/python3.12/site-packages (from pandas<2.3,>=1.1.5->nncf->-r requirements.txt (line 12)) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas<2.3,>=1.1.5->nncf->-r requirements.txt (line 12))\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<2.3,>=1.1.5->nncf->-r requirements.txt (line 12))\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pyparsing>=3.0.9 (from pydot<=3.0.4,>=1.4.1->nncf->-r requirements.txt (line 12))\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets>=1.4.0->optimum-intel==1.24.0->-r requirements.txt (line 10))\n",
      "  Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets>=1.4.0->optimum-intel==1.24.0->-r requirements.txt (line 10))\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from datasets>=1.4.0->optimum-intel==1.24.0->-r requirements.txt (line 10))\n",
      "  Using cached xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets>=1.4.0->optimum-intel==1.24.0->-r requirements.txt (line 10))\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec (from torch==2.7.1->-r requirements.txt (line 6))\n",
      "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.4.0->optimum-intel==1.24.0->-r requirements.txt (line 10))\n",
      "  Using cached aiohttp-3.12.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.4.0->optimum-intel==1.24.0->-r requirements.txt (line 10))\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.4.0->optimum-intel==1.24.0->-r requirements.txt (line 10))\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.4.0->optimum-intel==1.24.0->-r requirements.txt (line 10))\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.4.0->optimum-intel==1.24.0->-r requirements.txt (line 10))\n",
      "  Using cached frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.4.0->optimum-intel==1.24.0->-r requirements.txt (line 10))\n",
      "  Using cached multidict-6.6.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.4.0->optimum-intel==1.24.0->-r requirements.txt (line 10))\n",
      "  Using cached propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.4.0->optimum-intel==1.24.0->-r requirements.txt (line 10))\n",
      "  Using cached yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
      "Collecting idna>=2.0 (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.4.0->optimum-intel==1.24.0->-r requirements.txt (line 10))\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.2.0->nncf->-r requirements.txt (line 12))\n",
      "  Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.2.0->nncf->-r requirements.txt (line 12))\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.2.0->nncf->-r requirements.txt (line 12))\n",
      "  Using cached rpds_py-0.26.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting matplotlib>=3 (from pymoo>=0.6.0.1->nncf->-r requirements.txt (line 12))\n",
      "  Using cached matplotlib-3.10.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting autograd>=1.4 (from pymoo>=0.6.0.1->nncf->-r requirements.txt (line 12))\n",
      "  Using cached autograd-1.8.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting cma>=3.2.2 (from pymoo>=0.6.0.1->nncf->-r requirements.txt (line 12))\n",
      "  Downloading cma-4.3.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting alive-progress (from pymoo>=0.6.0.1->nncf->-r requirements.txt (line 12))\n",
      "  Using cached alive_progress-3.3.0-py3-none-any.whl.metadata (72 kB)\n",
      "Collecting Deprecated (from pymoo>=0.6.0.1->nncf->-r requirements.txt (line 12))\n",
      "  Using cached Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=3->pymoo>=0.6.0.1->nncf->-r requirements.txt (line 12))\n",
      "  Using cached contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=3->pymoo>=0.6.0.1->nncf->-r requirements.txt (line 12))\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3->pymoo>=0.6.0.1->nncf->-r requirements.txt (line 12))\n",
      "  Using cached fonttools-4.59.0-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (107 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib>=3->pymoo>=0.6.0.1->nncf->-r requirements.txt (line 12))\n",
      "  Using cached kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/eze/openvino/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<2.3,>=1.1.5->nncf->-r requirements.txt (line 12)) (1.17.0)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->transformers==4.52.4->-r requirements.txt (line 5))\n",
      "  Using cached charset_normalizer-3.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers==4.52.4->-r requirements.txt (line 5))\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers==4.52.4->-r requirements.txt (line 5))\n",
      "  Using cached certifi-2025.7.14-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=13.5.2->nncf->-r requirements.txt (line 12))\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/eze/openvino/.venv/lib/python3.12/site-packages (from rich>=13.5.2->nncf->-r requirements.txt (line 12)) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=13.5.2->nncf->-r requirements.txt (line 12))\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn>=0.24.0->nncf->-r requirements.txt (line 12))\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=0.24.0->nncf->-r requirements.txt (line 12))\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch==2.7.1->-r requirements.txt (line 6))\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting about-time==4.2.1 (from alive-progress->pymoo>=0.6.0.1->nncf->-r requirements.txt (line 12))\n",
      "  Using cached about_time-4.2.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting graphemeu==0.7.2 (from alive-progress->pymoo>=0.6.0.1->nncf->-r requirements.txt (line 12))\n",
      "  Using cached graphemeu-0.7.2-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting wrapt<2,>=1.10 (from Deprecated->pymoo>=0.6.0.1->nncf->-r requirements.txt (line 12))\n",
      "  Using cached wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.7.1->-r requirements.txt (line 6))\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Using cached openvino-2025.2.0-19140-cp312-cp312-manylinux2014_x86_64.whl (47.6 MB)\n",
      "Using cached numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
      "Downloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl (821.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.0/821.0 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.22.1-cp312-cp312-manylinux_2_28_x86_64.whl (7.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.28.2-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n",
      "Using cached sentencepiece-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Downloading optimum_intel-1.24.0-py3-none-any.whl (348 kB)\n",
      "Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.34.1-py3-none-any.whl (558 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m558.8/558.8 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Downloading optimum-1.26.1-py3-none-any.whl (424 kB)\n",
      "Using cached tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Using cached nncf-2.17.0-py3-none-any.whl (1.4 MB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
      "Using cached pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "Using cached pydot-3.0.4-py3-none-any.whl (35 kB)\n",
      "Downloading av-15.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (40.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Using cached aiohttp-3.12.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "Using cached multidict-6.6.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
      "Using cached yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached jsonschema-4.25.0-py3-none-any.whl (89 kB)\n",
      "Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Using cached natsort-8.4.0-py3-none-any.whl (38 kB)\n",
      "Using cached openvino_telemetry-2025.2.0-py3-none-any.whl (25 kB)\n",
      "Using cached propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (224 kB)\n",
      "Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pymoo-0.6.1.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
      "Using cached autograd-1.8.0-py3-none-any.whl (51 kB)\n",
      "Downloading cma-4.3.0-py3-none-any.whl (295 kB)\n",
      "Using cached matplotlib-3.10.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "Using cached contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.59.0-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
      "Using cached kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (767 kB)\n",
      "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Using cached regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (148 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached certifi-2025.7.14-py3-none-any.whl (162 kB)\n",
      "Downloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached rpds_py-0.26.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (386 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Using cached scikit_learn-1.7.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n",
      "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Using cached scipy-1.16.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.1 MB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached alive_progress-3.3.0-py3-none-any.whl (78 kB)\n",
      "Using cached about_time-4.2.1-py3-none-any.whl (13 kB)\n",
      "Using cached graphemeu-0.7.2-py3-none-any.whl (22 kB)\n",
      "Using cached Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Using cached wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
      "Using cached onnx-1.18.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
      "Using cached xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Installing collected packages: sentencepiece, pytz, openvino-telemetry, nvidia-cusparselt-cu12, mpmath, xxhash, wrapt, urllib3, tzdata, typing-extensions, tqdm, threadpoolctl, tabulate, sympy, setuptools, safetensors, rpds-py, regex, pyyaml, pyparsing, pyarrow, protobuf, propcache, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, ninja, networkx, natsort, multidict, mdurl, MarkupSafe, kiwisolver, joblib, idna, hf-xet, graphemeu, fsspec, frozenlist, fonttools, filelock, dill, cycler, charset_normalizer, certifi, av, attrs, aiohappyeyeballs, about-time, yarl, triton, scipy, requests, referencing, pydot, pandas, openvino, opencv-python, onnx, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, multiprocess, markdown-it-py, jinja2, Deprecated, contourpy, cma, autograd, alive-progress, aiosignal, scikit-learn, rich, nvidia-cusolver-cu12, matplotlib, jsonschema-specifications, huggingface_hub, aiohttp, torch, tokenizers, pymoo, jsonschema, transformers, torchvision, nncf, datasets, optimum, optimum-intel\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96/96\u001b[0m [optimum-intel]um-intel]ets]on]]ub]cu12]2]\n",
      "\u001b[1A\u001b[2KSuccessfully installed Deprecated-1.2.18 MarkupSafe-3.0.2 about-time-4.2.1 aiohappyeyeballs-2.6.1 aiohttp-3.12.14 aiosignal-1.4.0 alive-progress-3.3.0 attrs-25.3.0 autograd-1.8.0 av-15.0.0 certifi-2025.7.14 charset_normalizer-3.4.2 cma-4.3.0 contourpy-1.3.2 cycler-0.12.1 datasets-4.0.0 dill-0.3.8 filelock-3.18.0 fonttools-4.59.0 frozenlist-1.7.0 fsspec-2025.3.0 graphemeu-0.7.2 hf-xet-1.1.5 huggingface_hub-0.34.1 idna-3.10 jinja2-3.1.6 joblib-1.5.1 jsonschema-4.25.0 jsonschema-specifications-2025.4.1 kiwisolver-1.4.8 markdown-it-py-3.0.0 matplotlib-3.10.3 mdurl-0.1.2 mpmath-1.3.0 multidict-6.6.3 multiprocess-0.70.16 natsort-8.4.0 networkx-3.4.2 ninja-1.11.1.4 nncf-2.17.0 numpy-2.2.6 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 onnx-1.18.0 opencv-python-4.11.0.86 openvino-2025.2.0 openvino-telemetry-2025.2.0 optimum-1.26.1 optimum-intel-1.24.0 pandas-2.2.3 pillow-11.3.0 propcache-0.3.2 protobuf-5.28.2 pyarrow-21.0.0 pydot-3.0.4 pymoo-0.6.1.5 pyparsing-3.2.3 pytz-2025.2 pyyaml-6.0.2 referencing-0.36.2 regex-2024.11.6 requests-2.32.4 rich-14.1.0 rpds-py-0.26.0 safetensors-0.5.3 scikit-learn-1.7.1 scipy-1.16.0 sentencepiece-0.2.0 setuptools-80.9.0 sympy-1.14.0 tabulate-0.9.0 threadpoolctl-3.6.0 tokenizers-0.21.2 torch-2.7.1 torchvision-0.22.1 tqdm-4.67.1 transformers-4.52.4 triton-3.3.1 typing-extensions-4.14.1 tzdata-2025.2 urllib3-2.5.0 wrapt-1.17.2 xxhash-3.5.0 yarl-1.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7b1565c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eze/openvino/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  6.60it/s]\n",
      "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "/home/eze/openvino/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:556: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  or not self.key_cache[layer_idx].numel()  # the layer has no cache\n",
      "/home/eze/openvino/.venv/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:589: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if sequence_length != 1:\n",
      "/home/eze/openvino/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:540: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  not self.key_cache[layer_idx].numel()  # prefers not t.numel() to len(t) == 0 to export the model\n",
      "/home/eze/openvino/.venv/lib/python3.12/site-packages/transformers/integrations/sdpa_attention.py:47: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  is_causal = query.shape[2] > 1 and causal_mask is None\n",
      "/home/eze/openvino/.venv/lib/python3.12/site-packages/transformers/models/clip/modeling_clip.py:219: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if not interpolate_pos_encoding and (height != self.image_size or width != self.image_size):\n",
      "/home/eze/openvino/.venv/lib/python3.12/site-packages/transformers/models/llava_next_video/modeling_llava_next_video.py:154: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  ori_width = int(math.sqrt(image_features.shape[1] * self.image_size // self.image_size))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:Statistics of the bitwidth distribution:\n",
      "┍━━━━━━━━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┑\n",
      "│ Weight compression mode   │ % all parameters (layers)   │ % ratio-defining parameters (layers)   │\n",
      "┝━━━━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┥\n",
      "│ int8_asym                 │ 100% (225 / 225)            │ 100% (225 / 225)                       │\n",
      "┕━━━━━━━━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┙\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/eze/openvino/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/eze/openvino/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save model to OpenVINO format\n",
    "\n",
    "from optimum.intel.openvino import OVModelForVisualCausalLM\n",
    "\n",
    "# First time: export and save\n",
    "model = OVModelForVisualCausalLM.from_pretrained(\n",
    "    \"llava-hf/LLaVA-NeXT-Video-7B-hf\", \n",
    "    export=True,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "model.save_pretrained(\"./llava_openvino_model\")\n",
    "\n",
    "# Future times: load from local saved version (much faster)\n",
    "model = OVModelForVisualCausalLM.from_pretrained(\"./llava_openvino_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a74a9c",
   "metadata": {},
   "source": [
    "# Upload OV model to HF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42ede3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model card created: README.md\n"
     ]
    }
   ],
   "source": [
    "# Create model card and upload to Hugging Face Hub\n",
    "\n",
    "from huggingface_hub import HfApi, create_repo\n",
    "import os\n",
    "\n",
    "# Replace with your desired repo name\n",
    "REPO_NAME = \"llava-next-video-openvino\"  # Change this to your preferred name\n",
    "HF_USERNAME = \"ezelanza\"  # Replace with your HF username\n",
    "\n",
    "# Create model card content\n",
    "model_card = \"\"\"---\n",
    "license: apache-2.0\n",
    "base_model: llava-hf/LLaVA-NeXT-Video-7B-hf\n",
    "tags:\n",
    "- openvino\n",
    "- llava\n",
    "- multimodal\n",
    "- video\n",
    "- visual-question-answering\n",
    "---\n",
    "\n",
    "# LLaVA-NeXT-Video OpenVINO Model\n",
    "\n",
    "This is an OpenVINO optimized version of the LLaVA-NeXT-Video-7B-hf model.\n",
    "\n",
    "## Model Description\n",
    "- **Base Model**: llava-hf/LLaVA-NeXT-Video-7B-hf\n",
    "- **Optimization**: Converted to OpenVINO format for efficient inference\n",
    "- **Size**: ~7B parameters\n",
    "\n",
    "## Usage\n",
    "\n",
    "```python\n",
    "from optimum.intel.openvino import OVModelForVisualCausalLM\n",
    "\n",
    "model = OVModelForVisualCausalLM.from_pretrained(\"YOUR_USERNAME/llava-next-video-openvino\")\n",
    "```\n",
    "\n",
    "## License\n",
    "This model inherits the license from the original LLaVA-NeXT model.\n",
    "\"\"\"\n",
    "\n",
    "# Save model card\n",
    "with open(\"README.md\", \"w\") as f:\n",
    "    f.write(model_card)\n",
    "\n",
    "print(\"Model card created: README.md\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d419ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to: https://huggingface.co/settings/tokens\n",
      "Create a new token with WRITE permissions\n",
      "\n",
      "Repository created/exists: https://huggingface.co/ezelanza/llava-next-video-openvino\n",
      "Uploading model files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "openvino_language_model.bin:   0%|          | 0.00/26.2G [00:00<?, ?B/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "openvino_vision_resampler_model.bin: 100%|██████████| 100/100 [00:00<00:00, 1.85kB/s]\n",
      "openvino_language_model.bin:   0%|          | 9.37M/26.2G [00:00<04:39, 93.6MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_language_model.bin:   0%|          | 26.2M/26.2G [00:00<12:48, 34.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_language_model.bin:   0%|          | 52.4M/26.2G [00:01<07:52, 55.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_language_model.bin:   0%|          | 78.5M/26.2G [00:01<06:22, 68.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin: 100%|██████████| 83.9M/83.9M [00:01<00:00, 57.0MB/s]\n",
      "\n",
      "\n",
      "openvino_language_model.bin:   0%|          | 105M/26.2G [00:01<05:46, 75.3MB/s] \n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_language_model.bin:   1%|          | 131M/26.2G [00:01<05:46, 75.0MB/s]\n",
      "\n",
      "openvino_language_model.bin:   1%|          | 155M/26.2G [00:02<04:32, 95.6MB/s]\n",
      "\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   1%|          | 168M/26.2G [00:02<05:25, 79.9MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_language_model.bin:   1%|          | 183M/26.2G [00:02<07:04, 61.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   1%|          | 209M/26.2G [00:03<06:11, 69.9MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_language_model.bin:   1%|          | 236M/26.2G [00:03<06:44, 64.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   1%|          | 262M/26.2G [00:03<06:12, 69.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_language_model.bin:   1%|          | 288M/26.2G [00:04<06:20, 68.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   1%|          | 313M/26.2G [00:04<04:54, 87.7MB/s]\n",
      "\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   1%|          | 326M/26.2G [00:04<06:06, 70.4MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_language_model.bin:   1%|▏         | 340M/26.2G [00:04<07:02, 61.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_language_model.bin:   1%|▏         | 366M/26.2G [00:05<07:44, 55.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_language_model.bin:   2%|▏         | 393M/26.2G [00:05<07:09, 60.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_language_model.bin:   2%|▏         | 419M/26.2G [00:06<06:59, 61.4MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   2%|▏         | 445M/26.2G [00:06<07:14, 59.2MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   2%|▏         | 471M/26.2G [00:07<07:04, 60.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_language_model.bin:   2%|▏         | 519M/26.2G [00:07<05:09, 83.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   2%|▏         | 531M/26.2G [00:08<07:20, 58.2MB/s]\n",
      "\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   2%|▏         | 550M/26.2G [00:08<07:01, 60.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "openvino_text_embeddings_model.bin: 100%|██████████| 525M/525M [00:08<00:00, 59.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   3%|▎         | 707M/26.2G [00:11<06:20, 66.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   3%|▎         | 733M/26.2G [00:11<08:01, 52.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   3%|▎         | 759M/26.2G [00:12<07:33, 56.1MB/s]\n",
      "\n",
      "openvino_language_model.bin:   3%|▎         | 785M/26.2G [00:12<07:00, 60.3MB/s]\n",
      "\n",
      "openvino_language_model.bin:   3%|▎         | 811M/26.2G [00:12<06:42, 63.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   3%|▎         | 864M/26.2G [00:14<07:57, 53.0MB/s]\n",
      "\n",
      "openvino_language_model.bin:   3%|▎         | 898M/26.2G [00:14<06:26, 65.3MB/s]\n",
      "\n",
      "openvino_language_model.bin:   4%|▎         | 916M/26.2G [00:14<06:28, 65.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   4%|▎         | 968M/26.2G [00:15<05:22, 78.1MB/s]\n",
      "\n",
      "openvino_language_model.bin:   4%|▍         | 994M/26.2G [00:15<04:09, 101MB/s] \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   4%|▍         | 1.01G/26.2G [00:16<06:49, 61.4MB/s]\n",
      "\n",
      "openvino_language_model.bin:   4%|▍         | 1.02G/26.2G [00:16<07:09, 58.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   4%|▍         | 1.05G/26.2G [00:16<06:32, 64.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   4%|▍         | 1.07G/26.2G [00:17<07:56, 52.7MB/s]\n",
      "\n",
      "openvino_language_model.bin:   4%|▍         | 1.10G/26.2G [00:17<07:24, 56.3MB/s]\n",
      "\n",
      "openvino_language_model.bin:   4%|▍         | 1.12G/26.2G [00:17<05:51, 71.3MB/s]\n",
      "\n",
      "openvino_language_model.bin:   4%|▍         | 1.13G/26.2G [00:17<06:07, 68.1MB/s]\n",
      "\n",
      "openvino_language_model.bin:   4%|▍         | 1.15G/26.2G [00:18<06:30, 64.1MB/s]\n",
      "\n",
      "openvino_language_model.bin:   5%|▍         | 1.18G/26.2G [00:18<05:47, 71.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   5%|▍         | 1.20G/26.2G [00:19<06:02, 68.8MB/s]\n",
      "\n",
      "openvino_language_model.bin:   5%|▍         | 1.23G/26.2G [00:19<05:33, 74.7MB/s]\n",
      "\n",
      "openvino_language_model.bin:   5%|▍         | 1.27G/26.2G [00:19<04:46, 86.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   5%|▍         | 1.29G/26.2G [00:20<06:51, 60.4MB/s]\n",
      "\n",
      "openvino_vision_embeddings_model.bin: 100%|██████████| 1.16G/1.16G [00:20<00:00, 56.8MB/s]\n",
      "openvino_language_model.bin: 100%|██████████| 26.2G/26.2G [07:28<00:00, 58.3MB/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Upload 5 LFS files: 100%|██████████| 5/5 [07:29<00:00, 89.82s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model uploaded successfully!\n",
      "🔗 View your model at: https://huggingface.co/ezelanza/ezelanza/llava-next-video-openvino\n"
     ]
    }
   ],
   "source": [
    "# Upload model to Hugging Face Hub\n",
    "\n",
    "from huggingface_hub import HfApi\n",
    "import os\n",
    "# Login to Hugging Face\n",
    "\n",
    "from huggingface_hub import login\n",
    "import getpass\n",
    "\n",
    "print(\"Go to: https://huggingface.co/settings/tokens\")\n",
    "print(\"Create a new token with WRITE permissions\")\n",
    "print()\n",
    "\n",
    "token = getpass.getpass(\"Enter your HF token: \")\n",
    "login(token=token)\n",
    "\n",
    "# Configuration - UPDATE THESE VALUES\n",
    "REPO_NAME = \"ezelanza/llava-next-video-openvino\"  # Your desired repo name\n",
    "# The username will be automatically detected from your login\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "# Create repository\n",
    "try:\n",
    "    repo_url = api.create_repo(\n",
    "        repo_id=REPO_NAME,\n",
    "        exist_ok=True,\n",
    "        repo_type=\"model\"\n",
    "    )\n",
    "    print(f\"Repository created/exists: {repo_url}\")\n",
    "except Exception as e:\n",
    "    print(f\"Repository creation error: {e}\")\n",
    "\n",
    "# Upload model files if they exist\n",
    "if os.path.exists(\"./llava_openvino_model\"):\n",
    "    print(\"Uploading model files...\")\n",
    "    api.upload_folder(\n",
    "        folder_path=\"./llava_openvino_model\",\n",
    "        repo_id=REPO_NAME,\n",
    "        repo_type=\"model\"\n",
    "    )\n",
    "    \n",
    "    # Upload README\n",
    "    if os.path.exists(\"README.md\"):\n",
    "        api.upload_file(\n",
    "            path_or_fileobj=\"README.md\",\n",
    "            path_in_repo=\"README.md\",\n",
    "            repo_id=REPO_NAME,\n",
    "            repo_type=\"model\"\n",
    "        )\n",
    "    \n",
    "    print(f\"✅ Model uploaded successfully!\")\n",
    "    print(f\"🔗 View your model at: https://huggingface.co/{api.whoami()['name']}/{REPO_NAME}\")\n",
    "else:\n",
    "    print(\"❌ Model directory './llava_openvino_model' not found.\")\n",
    "    print(\"Run the first cell to save the model first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbf6f8f",
   "metadata": {},
   "source": [
    "# Load the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84aca11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to: https://huggingface.co/settings/tokens\n",
      "Create a new token with WRITE permissions\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "from optimum.intel.openvino import OVModelForVisualCausalLM\n",
    "from transformers import LlavaNextVideoProcessor\n",
    "from huggingface_hub import login\n",
    "import getpass\n",
    "\n",
    "print(\"Go to: https://huggingface.co/settings/tokens\")\n",
    "print(\"Create a new token with WRITE permissions\")\n",
    "print()\n",
    "\n",
    "token = getpass.getpass(\"Enter your HF token: \")\n",
    "login(token=token)\n",
    "model_id = \"ezelanza/llava-next-video-openvino\"\n",
    "\n",
    "\n",
    "model = OVModelForVisualCausalLM.from_pretrained(model_id)\n",
    "processor = LlavaNextVideoProcessor.from_pretrained(\"llava-hf/LLaVA-NeXT-Video-7B-hf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0758349",
   "metadata": {},
   "source": [
    "# Optimize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "438a6d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimum.intel import OVQuantizationConfig, OVWeightQuantizationConfig, OVPipelineQuantizationConfig\n",
    "\n",
    "dataset, num_samples = \"contextual\", 50\n",
    "\n",
    "# weight-only 8bit\n",
    "woq_8bit = OVWeightQuantizationConfig(bits=8)\n",
    "\n",
    "# weight-only 4bit\n",
    "woq_4bit = OVWeightQuantizationConfig(bits=4, group_size=16)\n",
    "\n",
    "# static quantization\n",
    "static_8bit = OVQuantizationConfig(bits=8, dataset=dataset, num_samples=num_samples)\n",
    "\n",
    "# pipeline quantization: applying different quantization on each components\n",
    "ppl_q = OVPipelineQuantizationConfig(\n",
    "    quantization_configs={\n",
    "        \"lm_model\": OVQuantizationConfig(bits=8),\n",
    "        \"multimodal_model\": OVWeightQuantizationConfig(bits=8),\n",
    "        \"text_embeddings_model\": OVWeightQuantizationConfig(bits=8),\n",
    "        \"vision_embeddings_model\": OVWeightQuantizationConfig(bits=8),\n",
    "        \"vision_model\": OVWeightQuantizationConfig(bits=8) \n",
    "    },\n",
    "    dataset=dataset,\n",
    "    num_samples=num_samples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42edb4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:Statistics of the bitwidth distribution:\n",
      "┍━━━━━━━━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┑\n",
      "│ Weight compression mode   │ % all parameters (layers)   │ % ratio-defining parameters (layers)   │\n",
      "┝━━━━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┥\n",
      "│ int8_asym                 │ 100% (225 / 225)            │ 100% (225 / 225)                       │\n",
      "┕━━━━━━━━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┙\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/emlanza/Repos/GitHub repos/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/emlanza/Repos/GitHub repos/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:Statistics of the bitwidth distribution:\n",
      "┍━━━━━━━━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┑\n",
      "│ Weight compression mode   │ % all parameters (layers)   │ % ratio-defining parameters (layers)   │\n",
      "┝━━━━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┥\n",
      "│ int8_sym                  │ 100% (1 / 1)                │ 100% (1 / 1)                           │\n",
      "┕━━━━━━━━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┙\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:Statistics of the bitwidth distribution:\n",
      "┍━━━━━━━━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┑\n",
      "│ Weight compression mode   │ % all parameters (layers)   │ % ratio-defining parameters (layers)   │\n",
      "┝━━━━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┥\n",
      "│ int8_sym                  │ 100% (139 / 139)            │ 100% (139 / 139)                       │\n",
      "┕━━━━━━━━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┙\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(44709) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(44710) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(44711) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:Statistics of the bitwidth distribution:\n",
      "┍━━━━━━━━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┑\n",
      "│ Weight compression mode   │ % all parameters (layers)   │ % ratio-defining parameters (layers)   │\n",
      "┝━━━━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┥\n",
      "┕━━━━━━━━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┙\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(44712) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(44713) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(44714) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(44715) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(44716) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(44717) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(44718) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(44719) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(44720) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(44721) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(44722) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(44723) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:Statistics of the bitwidth distribution:\n",
      "┍━━━━━━━━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┑\n",
      "│ Weight compression mode   │ % all parameters (layers)   │ % ratio-defining parameters (layers)   │\n",
      "┝━━━━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┥\n",
      "│ int8_sym                  │ 100% (2 / 2)                │ 100% (2 / 2)                           │\n",
      "┕━━━━━━━━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┙\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(44724) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(44725) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(44726) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(44727) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "from optimum.intel import OVModelForVisualCausalLM, OVWeightQuantizationConfig\n",
    "\n",
    "model_id = \"ezelanza/llava-next-video-openvino\"\n",
    "\n",
    "q_model = OVModelForVisualCausalLM.from_pretrained(model_id, quantization_config=woq_8bit)\n",
    "int8_model_path = \"llava_next_video_int8\"\n",
    "q_model.save_pretrained(int8_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5b2186b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to: https://huggingface.co/settings/tokens\n",
      "Create a new token with WRITE permissions\n",
      "\n",
      "Repository created/exists: https://huggingface.co/ezelanza/llava-next-video-openvino-int8\n",
      "Uploading model files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "openvino_multi_modal_projector_model.bin:   0%|          | 0.00/21.0M [00:00<?, ?B/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A'(MaxRetryError('HTTPSConnectionPool(host=\\'hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com\\', port=443): Max retries exceeded with url: /repos/60/90/6090cc385ffa8242599cb9933ddf89c49f0a95df92db8c4cb15f904cbf37cfa3/0e6fb96fcab98773f613fce6bc690e2c43dc5d7e0bef3bdfe207d9431d5b4480?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQLC2QXPN7%2F20250725%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250725T141644Z&X-Amz-Expires=86400&X-Amz-Signature=20006e0121fff48b85bd1a3ce0e5a655505162d03214475a1fdec4d4d9d4eed7&X-Amz-SignedHeaders=host&partNumber=1&uploadId=ygZb40kTtVIqmuflcTHo6zIhCbPRhzCVz84KiAdZ3XPMLpdjBu8LDcf0Yve.xTDtAVAUtbUxBKgisnbkNIsts5VfnMSQo3oP_a9Hak.yYjdP9F7q8BtjKQSudB30_ffT&x-id=UploadPart (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x709b6762d0>: Failed to resolve \\'hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com\\' ([Errno 8] nodename nor servname provided, or not known)\"))'), '(Request ID: ddf58be3-c0c8-4322-b64a-20c5d5c7f992)')' thrown while requesting PUT https://hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com/repos/60/90/6090cc385ffa8242599cb9933ddf89c49f0a95df92db8c4cb15f904cbf37cfa3/0e6fb96fcab98773f613fce6bc690e2c43dc5d7e0bef3bdfe207d9431d5b4480?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQLC2QXPN7%2F20250725%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250725T141644Z&X-Amz-Expires=86400&X-Amz-Signature=20006e0121fff48b85bd1a3ce0e5a655505162d03214475a1fdec4d4d9d4eed7&X-Amz-SignedHeaders=host&partNumber=1&uploadId=ygZb40kTtVIqmuflcTHo6zIhCbPRhzCVz84KiAdZ3XPMLpdjBu8LDcf0Yve.xTDtAVAUtbUxBKgisnbkNIsts5VfnMSQo3oP_a9Hak.yYjdP9F7q8BtjKQSudB30_ffT&x-id=UploadPart\n",
      "Retrying in 1s [Retry 1/5].\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "openvino_vision_resampler_model.bin: 100%|██████████| 100/100 [00:00<00:00, 129B/s]\n",
      "openvino_multi_modal_projector_model.bin:  32%|███▏      | 6.68M/21.0M [00:09<00:14, 1.00MB/s]\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  33%|███▎      | 6.95M/21.0M [00:09<00:12, 1.09MB/s]\n",
      "openvino_multi_modal_projector_model.bin:  37%|███▋      | 7.77M/21.0M [00:10<00:16, 796kB/s] \n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  39%|███▉      | 8.21M/21.0M [00:10<00:17, 738kB/s]\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  40%|████      | 8.50M/21.0M [00:11<00:15, 831kB/s]\n",
      "openvino_multi_modal_projector_model.bin:  41%|████      | 8.60M/21.0M [00:11<00:14, 870kB/s]\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  42%|████▏     | 8.80M/21.0M [00:11<00:15, 808kB/s]\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  43%|████▎     | 9.01M/21.0M [00:11<00:15, 780kB/s]\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  44%|████▎     | 9.18M/21.0M [00:12<00:16, 710kB/s]\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  45%|████▌     | 9.50M/21.0M [00:12<00:16, 705kB/s]\n",
      "\u001b[A\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  46%|████▌     | 9.72M/21.0M [00:12<00:14, 805kB/s]\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  47%|████▋     | 9.80M/21.0M [00:13<00:14, 797kB/s]\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  47%|████▋     | 9.90M/21.0M [00:13<00:13, 813kB/s]\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  47%|████▋     | 9.98M/21.0M [00:13<00:14, 787kB/s]\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  48%|████▊     | 10.1M/21.0M [00:13<00:15, 721kB/s]\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  49%|████▊     | 10.2M/21.0M [00:13<00:13, 783kB/s]\n",
      "openvino_multi_modal_projector_model.bin:  49%|████▉     | 10.4M/21.0M [00:13<00:12, 850kB/s]\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  50%|████▉     | 10.5M/21.0M [00:13<00:11, 881kB/s]\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  50%|█████     | 10.6M/21.0M [00:13<00:11, 878kB/s]\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  51%|█████     | 10.7M/21.0M [00:14<00:11, 914kB/s]\n",
      "\u001b[A\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  51%|█████▏    | 10.8M/21.0M [00:14<00:10, 1.01MB/s]\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  52%|█████▏    | 11.0M/21.0M [00:14<00:08, 1.13MB/s]\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  53%|█████▎    | 11.1M/21.0M [00:14<00:07, 1.26MB/s]\n",
      "openvino_multi_modal_projector_model.bin:  54%|█████▎    | 11.3M/21.0M [00:14<00:07, 1.29MB/s]\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  54%|█████▍    | 11.4M/21.0M [00:14<00:07, 1.28MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  55%|█████▍    | 11.5M/21.0M [00:14<00:08, 1.06MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  55%|█████▌    | 11.6M/21.0M [00:14<00:09, 985kB/s] \n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  56%|█████▌    | 11.8M/21.0M [00:15<00:09, 935kB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  56%|█████▋    | 11.9M/21.0M [00:15<00:10, 884kB/s]\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  57%|█████▋    | 12.0M/21.0M [00:15<00:09, 1.00MB/s]\n",
      "\u001b[A\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  58%|█████▊    | 12.2M/21.0M [00:15<00:08, 1.09MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  59%|█████▊    | 12.3M/21.0M [00:15<00:07, 1.15MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  59%|█████▉    | 12.5M/21.0M [00:15<00:08, 1.06MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  60%|█████▉    | 12.6M/21.0M [00:15<00:08, 968kB/s] \n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  60%|██████    | 12.7M/21.0M [00:15<00:08, 973kB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  61%|██████    | 12.8M/21.0M [00:16<00:07, 1.05MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  62%|██████▏   | 12.9M/21.0M [00:16<00:09, 847kB/s] \n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  62%|██████▏   | 13.0M/21.0M [00:16<00:10, 736kB/s]\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  62%|██████▏   | 13.1M/21.0M [00:16<00:10, 751kB/s]\n",
      "openvino_multi_modal_projector_model.bin:  63%|██████▎   | 13.2M/21.0M [00:16<00:09, 783kB/s]\n",
      "\u001b[A\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  63%|██████▎   | 13.3M/21.0M [00:16<00:08, 865kB/s]\n",
      "\u001b[A\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  64%|██████▍   | 13.4M/21.0M [00:16<00:08, 885kB/s]\n",
      "\u001b[A\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  64%|██████▍   | 13.5M/21.0M [00:17<00:08, 889kB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  65%|██████▍   | 13.6M/21.0M [00:17<00:09, 798kB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  65%|██████▌   | 13.7M/21.0M [00:17<00:08, 845kB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  66%|██████▌   | 13.8M/21.0M [00:17<00:08, 842kB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  66%|██████▋   | 13.9M/21.0M [00:17<00:08, 794kB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  67%|██████▋   | 14.1M/21.0M [00:17<00:08, 863kB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  67%|██████▋   | 14.2M/21.0M [00:17<00:07, 909kB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  68%|██████▊   | 14.3M/21.0M [00:17<00:07, 904kB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  68%|██████▊   | 14.4M/21.0M [00:18<00:07, 863kB/s]\n",
      "\u001b[A\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  69%|██████▉   | 14.5M/21.0M [00:18<00:07, 903kB/s]\n",
      "openvino_multi_modal_projector_model.bin:  69%|██████▉   | 14.6M/21.0M [00:18<00:06, 959kB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  70%|██████▉   | 14.7M/21.0M [00:18<00:06, 961kB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  70%|███████   | 14.8M/21.0M [00:18<00:06, 988kB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  71%|███████   | 14.9M/21.0M [00:18<00:06, 939kB/s]\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  71%|███████▏  | 15.0M/21.0M [00:18<00:06, 868kB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  72%|███████▏  | 15.1M/21.0M [00:18<00:07, 790kB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  72%|███████▏  | 15.2M/21.0M [00:18<00:07, 774kB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  73%|███████▎  | 15.3M/21.0M [00:19<00:07, 810kB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  73%|███████▎  | 15.4M/21.0M [00:19<00:07, 800kB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  74%|███████▎  | 15.5M/21.0M [00:19<00:06, 841kB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  74%|███████▍  | 15.6M/21.0M [00:19<00:07, 725kB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  75%|███████▍  | 15.7M/21.0M [00:19<00:08, 618kB/s]\n",
      "openvino_multi_modal_projector_model.bin:  75%|███████▌  | 15.8M/21.0M [00:19<00:07, 725kB/s]\n",
      "\u001b[A\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  76%|███████▌  | 15.9M/21.0M [00:19<00:06, 734kB/s]\n",
      "\u001b[A\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  76%|███████▌  | 16.0M/21.0M [00:20<00:08, 570kB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  76%|███████▋  | 16.0M/21.0M [00:20<00:12, 399kB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  78%|███████▊  | 16.4M/21.0M [00:20<00:05, 890kB/s]\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  79%|███████▉  | 16.6M/21.0M [00:20<00:04, 943kB/s]\n",
      "openvino_multi_modal_projector_model.bin:  80%|████████  | 16.9M/21.0M [00:20<00:03, 1.34MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  81%|████████▏ | 17.1M/21.0M [00:20<00:02, 1.48MB/s]\n",
      "\u001b[A\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  82%|████████▏ | 17.3M/21.0M [00:21<00:02, 1.58MB/s]\n",
      "\u001b[A\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  83%|████████▎ | 17.5M/21.0M [00:21<00:02, 1.50MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  84%|████████▍ | 17.7M/21.0M [00:21<00:02, 1.33MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  85%|████████▍ | 17.8M/21.0M [00:21<00:02, 1.27MB/s]\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  86%|████████▌ | 18.0M/21.0M [00:21<00:02, 1.29MB/s]\n",
      "\u001b[A\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  86%|████████▋ | 18.1M/21.0M [00:21<00:02, 1.31MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  87%|████████▋ | 18.3M/21.0M [00:21<00:02, 1.32MB/s]\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  88%|████████▊ | 18.5M/21.0M [00:21<00:01, 1.37MB/s]\n",
      "openvino_multi_modal_projector_model.bin:  89%|████████▊ | 18.6M/21.0M [00:22<00:01, 1.44MB/s]\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  89%|████████▉ | 18.8M/21.0M [00:22<00:01, 1.26MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  90%|████████▉ | 18.9M/21.0M [00:22<00:01, 1.13MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  91%|█████████ | 19.0M/21.0M [00:22<00:01, 1.01MB/s]\n",
      "openvino_multi_modal_projector_model.bin:  91%|█████████ | 19.2M/21.0M [00:22<00:01, 972kB/s] \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  92%|█████████▏| 19.3M/21.0M [00:22<00:01, 1.00MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  92%|█████████▏| 19.4M/21.0M [00:22<00:01, 1.09MB/s]\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  93%|█████████▎| 19.6M/21.0M [00:23<00:01, 1.14MB/s]\n",
      "\u001b[A\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  94%|█████████▎| 19.7M/21.0M [00:23<00:01, 1.21MB/s]\n",
      "\u001b[A\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  94%|█████████▍| 19.9M/21.0M [00:23<00:00, 1.22MB/s]\n",
      "openvino_multi_modal_projector_model.bin:  95%|█████████▌| 20.0M/21.0M [00:23<00:00, 1.28MB/s]\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  96%|█████████▌| 20.1M/21.0M [00:23<00:00, 1.27MB/s]\n",
      "\u001b[A\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  97%|█████████▋| 20.3M/21.0M [00:23<00:00, 1.32MB/s]\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  97%|█████████▋| 20.5M/21.0M [00:23<00:00, 1.35MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  98%|█████████▊| 20.6M/21.0M [00:23<00:00, 1.22MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin:  99%|█████████▊| 20.7M/21.0M [00:23<00:00, 1.13MB/s]\n",
      "\u001b[A\n",
      "\n",
      "openvino_multi_modal_projector_model.bin:  99%|█████████▉| 20.9M/21.0M [00:24<00:00, 1.09MB/s]\n",
      "\u001b[A\n",
      "\n",
      "openvino_multi_modal_projector_model.bin: 100%|█████████▉| 21.0M/21.0M [00:24<00:00, 1.10MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin: 100%|██████████| 21.0M/21.0M [00:24<00:00, 857kB/s] \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "openvino_text_embeddings_model.bin: 100%|██████████| 131M/131M [01:47<00:00, 1.22MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "openvino_vision_embeddings_model.bin: 100%|██████████| 294M/294M [03:09<00:00, 1.55MB/s]\n",
      "openvino_language_model.bin: 100%|██████████| 6.61G/6.61G [31:01<00:00, 3.55MB/s]\n",
      "\n",
      "\n",
      "\n",
      "Upload 5 LFS files: 100%|██████████| 5/5 [31:01<00:00, 372.38s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model uploaded successfully!\n",
      "🔗 View your model at: https://huggingface.co/ezelanza/ezelanza/llava-next-video-openvino-int8\n"
     ]
    }
   ],
   "source": [
    "# Upload model to Hugging Face Hub\n",
    "\n",
    "from huggingface_hub import HfApi\n",
    "import os\n",
    "# Login to Hugging Face\n",
    "\n",
    "from huggingface_hub import login\n",
    "import getpass\n",
    "\n",
    "print(\"Go to: https://huggingface.co/settings/tokens\")\n",
    "print(\"Create a new token with WRITE permissions\")\n",
    "print()\n",
    "\n",
    "token = getpass.getpass(\"Enter your HF token: \")\n",
    "login(token=token)\n",
    "\n",
    "# Configuration - UPDATE THESE VALUES\n",
    "REPO_NAME = \"ezelanza/llava-next-video-openvino-int8\"  # Your desired repo name\n",
    "# The username will be automatically detected from your login\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "# Create repository\n",
    "try:\n",
    "    repo_url = api.create_repo(\n",
    "        repo_id=REPO_NAME,\n",
    "        exist_ok=True,\n",
    "        repo_type=\"model\"\n",
    "    )\n",
    "    print(f\"Repository created/exists: {repo_url}\")\n",
    "except Exception as e:\n",
    "    print(f\"Repository creation error: {e}\")\n",
    "\n",
    "# Upload model files if they exist\n",
    "if os.path.exists(\"./llava_next_video_int8\"):\n",
    "    print(\"Uploading model files...\")\n",
    "    api.upload_folder(\n",
    "        folder_path=\"./llava_next_video_int8\",\n",
    "        repo_id=REPO_NAME,\n",
    "        repo_type=\"model\"\n",
    "    )\n",
    "    \n",
    "    # Upload README\n",
    "    if os.path.exists(\"README.md\"):\n",
    "        api.upload_file(\n",
    "            path_or_fileobj=\"README.md\",\n",
    "            path_in_repo=\"README.md\",\n",
    "            repo_id=REPO_NAME,\n",
    "            repo_type=\"model\"\n",
    "        )\n",
    "    \n",
    "    print(f\"✅ Model uploaded successfully!\")\n",
    "    print(f\"🔗 View your model at: https://huggingface.co/{api.whoami()['name']}/{REPO_NAME}\")\n",
    "else:\n",
    "    print(\"❌ Model directory './llava_openvino_model' not found.\")\n",
    "    print(\"Run the first cell to save the model first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0a662c",
   "metadata": {},
   "source": [
    "# Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8436ca96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eze/openvino/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to: https://huggingface.co/settings/tokens\n",
      "Create a new token with WRITE permissions\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Unused or unrecognized kwargs: return_tensors.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download \n",
    "from transformers import LlavaNextVideoProcessor\n",
    "from optimum.intel.openvino import OVModelForVisualCausalLM\n",
    "from optimum.intel.openvino import OVModelForVisualCausalLM\n",
    "from transformers import LlavaNextVideoProcessor\n",
    "from huggingface_hub import login\n",
    "import getpass\n",
    "\n",
    "print(\"Go to: https://huggingface.co/settings/tokens\")\n",
    "print(\"Create a new token with WRITE permissions\")\n",
    "print()\n",
    "\n",
    "token = getpass.getpass(\"Enter your HF token: \")\n",
    "login(token=token)\n",
    "\n",
    "#load model in memory\n",
    "model_id = \"ezelanza/llava-next-video-openvino-int8\"\n",
    "\n",
    "video_path = hf_hub_download(repo_id=\"raushan-testing-hf/videos-test\", filename=\"sample_demo_1.mp4\", repo_type=\"dataset\")\n",
    "\n",
    "conversation = [\n",
    "    {\n",
    "\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"What is happening in the video?\"},\n",
    "            {\"type\": \"video\", \"path\": video_path},\n",
    "            ],\n",
    "    },\n",
    "]\n",
    "processor = LlavaNextVideoProcessor.from_pretrained(\"llava-hf/LLaVA-NeXT-Video-7B-hf\")\n",
    "model = OVModelForVisualCausalLM.from_pretrained(model_id)\n",
    "\n",
    "\n",
    "inputs = processor.apply_chat_template(\n",
    "    conversation,\n",
    "    num_frames=4,\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=True,\n",
    "    return_dict=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4e27fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL OUTPUT (video frames): USER: \n",
      "What is happening in the video? ASSISTANT: In the video, we see a young child sitting on a bed, wearing glasses and engrossed in reading a book. The child appears to be focused on the book, possibly reading or looking at the pictures. The room has a cozy and lived-in feel, with various items\n",
      "CAPTION GENERATED (video frames): In the video, we see a young child sitting on a bed, wearing glasses and engrossed in reading a book. The child appears to be focused on the book, possibly reading or looking at the pictures. The room has a cozy and lived-in feel, with various items\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(**inputs, max_new_tokens=60)\n",
    "    \n",
    "response = processor.batch_decode(\n",
    "        output,\n",
    "        skip_special_tokens=True,\n",
    "        clean_up_tokenization_spaces=True\n",
    "    )[0]\n",
    "    \n",
    "print(f\"MODEL OUTPUT (video frames): {response}\")\n",
    "    \n",
    "if \"ASSISTANT:\" in response:\n",
    "        description = response.split(\"ASSISTANT:\")[-1].strip()\n",
    "else:\n",
    "        description = response.strip()\n",
    "    \n",
    "print(f\"CAPTION GENERATED (video frames): {description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81b5078",
   "metadata": {},
   "source": [
    "# Extract from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4db87875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import time\n",
    "from transformers import LlavaNextVideoProcessor\n",
    "from optimum.intel.openvino import OVModelForVisualCausalLM\n",
    "\n",
    "def extract_video_frames(video_path, num_frames=4, width=320, height=240):\n",
    "    \"\"\"Extract evenly spaced frames from a video file.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video file\")\n",
    "        return []\n",
    "    \n",
    "    total_video_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    duration = total_video_frames / fps\n",
    "    \n",
    "    print(f\"Video info: {total_video_frames} frames, {fps:.1f} FPS, {duration:.1f} seconds\")\n",
    "    \n",
    "    # Calculate frame indices to extract (evenly spaced)\n",
    "    frame_indices = np.linspace(0, total_video_frames-1, num_frames, dtype=int)\n",
    "    \n",
    "    frames = []\n",
    "    for i, frame_idx in enumerate(frame_indices):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            # Resize frame to reduce processing time\n",
    "            frame_resized = cv2.resize(frame, (width, height))\n",
    "            # Convert BGR to RGB\n",
    "            frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame_rgb)\n",
    "            print(f\"Extracted frame {i+1}/{num_frames} at frame {frame_idx}\")\n",
    "    \n",
    "    cap.release()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97b50d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video info: 243 frames, 25.0 FPS, 9.7 seconds\n",
      "Extracted frame 1/4 at frame 0\n",
      "Extracted frame 2/4 at frame 80\n",
      "Extracted frame 3/4 at frame 161\n",
      "Extracted frame 4/4 at frame 242\n",
      "Saved frame 1 as video_frame_0.jpg\n",
      "Saved frame 2 as video_frame_1.jpg\n",
      "Saved frame 3 as video_frame_2.jpg\n",
      "Saved frame 4 as video_frame_3.jpg\n"
     ]
    }
   ],
   "source": [
    "    # Extract frames from video\n",
    "frames = extract_video_frames(video_path, num_frames=4, width=320, height=240)\n",
    "    \n",
    "# Save frames as temporary images\n",
    "frame_paths = []\n",
    "for i, frame in enumerate(frames):\n",
    "    frame_path = f\"video_frame_{i}.jpg\"\n",
    "    cv2.imwrite(frame_path, cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "    frame_paths.append(Path(frame_path))\n",
    "    print(f\"Saved frame {i+1} as {frame_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb24b07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL OUTPUT (video frames): USER: \n",
      "\n",
      "\n",
      "\n",
      "Describe what you see in these images. What is happening? ASSISTANT: In the image, there is a young child sitting on a bed, engrossed in reading a book. The child is wearing a light blue sleeveless top and glasses, and appears to be focused on the book in their hands. The bed has a patterned blanket,\n",
      "CAPTION GENERATED (video frames): In the image, there is a young child sitting on a bed, engrossed in reading a book. The child is wearing a light blue sleeveless top and glasses, and appears to be focused on the book in their hands. The bed has a patterned blanket,\n"
     ]
    }
   ],
   "source": [
    "# Use frames as images in conversation\n",
    "processor = LlavaNextVideoProcessor.from_pretrained(\"llava-hf/LLaVA-NeXT-Video-7B-hf\")\n",
    "model = OVModelForVisualCausalLM.from_pretrained(model_id)\n",
    "\n",
    "    \n",
    "conversation_with_frames = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Describe what you see in these images. What is happening?\"},\n",
    "                *[{\"type\": \"image\", \"image\": path.as_posix()} for path in frame_paths],\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    # Process with the same model and processor\n",
    "inputs_with_frames = processor.apply_chat_template(\n",
    "        conversation_with_frames,\n",
    "        num_frames=4,\n",
    "        add_generation_prompt=True,\n",
    "        tokenize=True,\n",
    "        return_dict=True\n",
    "    )\n",
    "    \n",
    "    # Generate response\n",
    "out_with_frames = model.generate(**inputs_with_frames, max_new_tokens=60)\n",
    "    \n",
    "response_with_frames = processor.batch_decode(\n",
    "        out_with_frames,\n",
    "        skip_special_tokens=True,\n",
    "        clean_up_tokenization_spaces=True\n",
    "    )[0]\n",
    "    \n",
    "print(f\"MODEL OUTPUT (video frames): {response_with_frames}\")\n",
    "    \n",
    "if \"ASSISTANT:\" in response_with_frames:\n",
    "        description_with_frames = response_with_frames.split(\"ASSISTANT:\")[-1].strip()\n",
    "else:\n",
    "        description_with_frames = response_with_frames.strip()\n",
    "    \n",
    "print(f\"CAPTION GENERATED (video frames): {description_with_frames}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccebf8ae",
   "metadata": {},
   "source": [
    "# EXtract from webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c821f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eze/openvino/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to: https://huggingface.co/settings/tokens\n",
      "Create a new token with WRITE permissions\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download \n",
    "from transformers import LlavaNextVideoProcessor\n",
    "from optimum.intel.openvino import OVModelForVisualCausalLM\n",
    "from optimum.intel.openvino import OVModelForVisualCausalLM\n",
    "from transformers import LlavaNextVideoProcessor\n",
    "from huggingface_hub import login\n",
    "import getpass\n",
    "\n",
    "print(\"Go to: https://huggingface.co/settings/tokens\")\n",
    "print(\"Create a new token with WRITE permissions\")\n",
    "print()\n",
    "\n",
    "token = getpass.getpass(\"Enter your HF token: \")\n",
    "login(token=token)\n",
    "\n",
    "#load model in memory\n",
    "model_id = \"ezelanza/llava-next-video-openvino-int8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fcb655b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import time\n",
    "from transformers import LlavaNextVideoProcessor\n",
    "from optimum.intel.openvino import OVModelForVisualCausalLM\n",
    "\n",
    "def capture_webcam_frames(duration_seconds=3, fps=4, width=320, height=240):\n",
    "    \"\"\"Capture frames from webcam for a specified duration automatically.\"\"\"\n",
    "    cap = cv2.VideoCapture(0)  # 0 for default webcam\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam\")\n",
    "        return []\n",
    "    \n",
    "    # Set resolution to reduce processing time\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 320)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "    \n",
    "    # Verify the resolution was set\n",
    "    actual_width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    actual_height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    print(f\"Webcam resolution set to: {actual_width}x{actual_height}\")\n",
    "\n",
    "    frames = []\n",
    "    total_frames = duration_seconds * fps\n",
    "    frame_interval = 1.0 / fps  # Time between frames\n",
    "    \n",
    "    print(f\"Capturing {total_frames} frames over {duration_seconds} seconds...\")\n",
    "    print(\"Starting in 3 seconds...\")\n",
    "    \n",
    "    # Countdown\n",
    "    for i in range(3, 0, -1):\n",
    "        print(f\"{i}...\")\n",
    "        time.sleep(1)\n",
    "    \n",
    "    print(\"Starting frame capture...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in range(total_frames):\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame_resized = cv2.resize(frame, (width, height))\n",
    "\n",
    "            # Convert BGR to RGB\n",
    "            frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame_rgb)\n",
    "            \n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f\"Captured frame {i+1}/{total_frames} at {elapsed_time:.1f}s\")\n",
    "            \n",
    "            # Wait for next frame time\n",
    "            if i < total_frames - 1:  # Don't wait after the last frame\n",
    "                time.sleep(frame_interval)\n",
    "    \n",
    "    cap.release()\n",
    "    print(\"Capture complete!\")\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dca22f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Webcam resolution set to: 320.0x240.0\n",
      "Capturing 12 frames over 3 seconds...\n",
      "Starting in 3 seconds...\n",
      "3...\n",
      "2...\n",
      "1...\n",
      "Starting frame capture...\n",
      "Captured frame 1/12 at 0.2s\n",
      "Captured frame 2/12 at 0.4s\n",
      "Captured frame 3/12 at 0.7s\n",
      "Captured frame 4/12 at 1.0s\n",
      "Captured frame 5/12 at 1.2s\n",
      "Captured frame 6/12 at 1.5s\n",
      "Captured frame 7/12 at 1.7s\n",
      "Captured frame 8/12 at 2.0s\n",
      "Captured frame 9/12 at 2.2s\n",
      "Captured frame 10/12 at 2.5s\n",
      "Captured frame 11/12 at 2.7s\n",
      "Captured frame 12/12 at 3.0s\n",
      "Capture complete!\n",
      "Saved frame 1 as webcam_frame_0.jpg\n",
      "Saved frame 2 as webcam_frame_1.jpg\n",
      "Saved frame 3 as webcam_frame_2.jpg\n",
      "Saved frame 4 as webcam_frame_3.jpg\n",
      "Saved frame 5 as webcam_frame_4.jpg\n",
      "Saved frame 6 as webcam_frame_5.jpg\n",
      "Saved frame 7 as webcam_frame_6.jpg\n",
      "Saved frame 8 as webcam_frame_7.jpg\n",
      "Saved frame 9 as webcam_frame_8.jpg\n",
      "Saved frame 10 as webcam_frame_9.jpg\n",
      "Saved frame 11 as webcam_frame_10.jpg\n",
      "Saved frame 12 as webcam_frame_11.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "frames = capture_webcam_frames(duration_seconds=3,fps=4)\n",
    "\n",
    "    # Save frames as temporary images\n",
    "frame_paths = []\n",
    "for i, frame in enumerate(frames):\n",
    "        frame_path = f\"webcam_frame_{i}.jpg\"\n",
    "        cv2.imwrite(frame_path, cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "        frame_paths.append(Path(frame_path))\n",
    "        print(f\"Saved frame {i+1} as {frame_path}\")\n",
    "    \n",
    "conversation = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Describe this video in one short sentence. What do you see happening? Describe it as if you were a person seeing it avoid saying 'IN the video'\"},\n",
    "                *[{\"type\": \"image\", \"image\": path.as_posix()} for path in frame_paths],\n",
    "            ],\n",
    "        },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ad51e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (16471 > 10250). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "processor = LlavaNextVideoProcessor.from_pretrained(\"llava-hf/LLaVA-NeXT-Video-7B-hf\")\n",
    "model = OVModelForVisualCausalLM.from_pretrained(model_id)\n",
    "\n",
    "\n",
    "inputs = processor.apply_chat_template(\n",
    "    conversation,\n",
    "    num_frames=4,\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=True,\n",
    "    return_dict=True\n",
    ")\n",
    "\n",
    "out = model.generate(**inputs, max_new_tokens=60)\n",
    "\n",
    "response = processor.batch_decode(\n",
    "                    out,\n",
    "                    skip_special_tokens=True,\n",
    "                    clean_up_tokenization_spaces=True\n",
    "                )[0]\n",
    "\n",
    "if \"ASSISTANT:\" in response:\n",
    "    description = response.split(\"ASSISTANT:\")[-1].strip()\n",
    "else:\n",
    "    # If no ASSISTANT marker, use the full response\n",
    "    description = response.strip()\n",
    "\n",
    "print(f\"CAPTION GENERATED: {description}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
