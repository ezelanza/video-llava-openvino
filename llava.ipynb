{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f17d903",
   "metadata": {},
   "source": [
    "# Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6281368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openvino==2025.2.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (2025.2.0)\n",
      "Requirement already satisfied: numpy==2.2.6 in /home/ubuntu/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (2.2.6)\n",
      "Requirement already satisfied: opencv-python==4.11.0.86 in /home/ubuntu/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (4.11.0.86)\n",
      "Requirement already satisfied: pillow==11.3.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (11.3.0)\n",
      "Requirement already satisfied: transformers==4.52.4 in /home/ubuntu/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (4.52.4)\n",
      "Requirement already satisfied: torch==2.7.1 in /home/ubuntu/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (2.7.1)\n",
      "Requirement already satisfied: torchvision==0.22.1 in /home/ubuntu/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (0.22.1)\n",
      "Requirement already satisfied: protobuf==5.28.2 in /home/ubuntu/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (5.28.2)\n",
      "Requirement already satisfied: sentencepiece==0.2.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (0.2.0)\n",
      "Requirement already satisfied: optimum-intel==1.24.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (1.24.0)\n",
      "Requirement already satisfied: huggingface_hub in /home/ubuntu/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 11)) (0.33.5)\n",
      "Requirement already satisfied: nncf in /home/ubuntu/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 12)) (2.17.0)\n",
      "Requirement already satisfied: av in /home/ubuntu/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 13)) (15.0.0)\n",
      "Requirement already satisfied: openvino-telemetry>=2023.2.1 in /home/ubuntu/.venv/lib/python3.12/site-packages (from openvino==2025.2.0->-r requirements.txt (line 1)) (2025.2.0)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/.venv/lib/python3.12/site-packages (from openvino==2025.2.0->-r requirements.txt (line 1)) (25.0)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/.venv/lib/python3.12/site-packages (from transformers==4.52.4->-r requirements.txt (line 5)) (3.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/.venv/lib/python3.12/site-packages (from transformers==4.52.4->-r requirements.txt (line 5)) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/.venv/lib/python3.12/site-packages (from transformers==4.52.4->-r requirements.txt (line 5)) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/ubuntu/.venv/lib/python3.12/site-packages (from transformers==4.52.4->-r requirements.txt (line 5)) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/ubuntu/.venv/lib/python3.12/site-packages (from transformers==4.52.4->-r requirements.txt (line 5)) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/ubuntu/.venv/lib/python3.12/site-packages (from transformers==4.52.4->-r requirements.txt (line 5)) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/.venv/lib/python3.12/site-packages (from transformers==4.52.4->-r requirements.txt (line 5)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from torch==2.7.1->-r requirements.txt (line 6)) (4.14.1)\n",
      "Requirement already satisfied: setuptools in /home/ubuntu/.venv/lib/python3.12/site-packages (from torch==2.7.1->-r requirements.txt (line 6)) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/ubuntu/.venv/lib/python3.12/site-packages (from torch==2.7.1->-r requirements.txt (line 6)) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/.venv/lib/python3.12/site-packages (from torch==2.7.1->-r requirements.txt (line 6)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/.venv/lib/python3.12/site-packages (from torch==2.7.1->-r requirements.txt (line 6)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/.venv/lib/python3.12/site-packages (from torch==2.7.1->-r requirements.txt (line 6)) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/ubuntu/.venv/lib/python3.12/site-packages (from torch==2.7.1->-r requirements.txt (line 6)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/ubuntu/.venv/lib/python3.12/site-packages (from torch==2.7.1->-r requirements.txt (line 6)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/ubuntu/.venv/lib/python3.12/site-packages (from torch==2.7.1->-r requirements.txt (line 6)) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/ubuntu/.venv/lib/python3.12/site-packages (from torch==2.7.1->-r requirements.txt (line 6)) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/ubuntu/.venv/lib/python3.12/site-packages (from torch==2.7.1->-r requirements.txt (line 6)) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/ubuntu/.venv/lib/python3.12/site-packages (from torch==2.7.1->-r requirements.txt (line 6)) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/ubuntu/.venv/lib/python3.12/site-packages (from torch==2.7.1->-r requirements.txt (line 6)) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/ubuntu/.venv/lib/python3.12/site-packages (from torch==2.7.1->-r requirements.txt (line 6)) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/ubuntu/.venv/lib/python3.12/site-packages (from torch==2.7.1->-r requirements.txt (line 6)) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/ubuntu/.venv/lib/python3.12/site-packages (from torch==2.7.1->-r requirements.txt (line 6)) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/ubuntu/.venv/lib/python3.12/site-packages (from torch==2.7.1->-r requirements.txt (line 6)) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/ubuntu/.venv/lib/python3.12/site-packages (from torch==2.7.1->-r requirements.txt (line 6)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/ubuntu/.venv/lib/python3.12/site-packages (from torch==2.7.1->-r requirements.txt (line 6)) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/ubuntu/.venv/lib/python3.12/site-packages (from torch==2.7.1->-r requirements.txt (line 6)) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/ubuntu/.venv/lib/python3.12/site-packages (from torch==2.7.1->-r requirements.txt (line 6)) (3.3.1)\n",
      "Requirement already satisfied: optimum==1.26.* in /home/ubuntu/.venv/lib/python3.12/site-packages (from optimum-intel==1.24.0->-r requirements.txt (line 10)) (1.26.1)\n",
      "Requirement already satisfied: datasets>=1.4.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from optimum-intel==1.24.0->-r requirements.txt (line 10)) (4.0.0)\n",
      "Requirement already satisfied: scipy in /home/ubuntu/.venv/lib/python3.12/site-packages (from optimum-intel==1.24.0->-r requirements.txt (line 10)) (1.16.0)\n",
      "Requirement already satisfied: onnx in /home/ubuntu/.venv/lib/python3.12/site-packages (from optimum-intel==1.24.0->-r requirements.txt (line 10)) (1.18.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/ubuntu/.venv/lib/python3.12/site-packages (from huggingface_hub->-r requirements.txt (line 11)) (1.1.5)\n",
      "Requirement already satisfied: jsonschema>=3.2.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from nncf->-r requirements.txt (line 12)) (4.25.0)\n",
      "Requirement already satisfied: natsort>=7.1.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from nncf->-r requirements.txt (line 12)) (8.4.0)\n",
      "Requirement already satisfied: ninja<1.12,>=1.10.0.post2 in /home/ubuntu/.venv/lib/python3.12/site-packages (from nncf->-r requirements.txt (line 12)) (1.11.1.4)\n",
      "Requirement already satisfied: pandas<2.3,>=1.1.5 in /home/ubuntu/.venv/lib/python3.12/site-packages (from nncf->-r requirements.txt (line 12)) (2.2.3)\n",
      "Requirement already satisfied: psutil in /home/ubuntu/.venv/lib/python3.12/site-packages (from nncf->-r requirements.txt (line 12)) (7.0.0)\n",
      "Requirement already satisfied: pydot<=3.0.4,>=1.4.1 in /home/ubuntu/.venv/lib/python3.12/site-packages (from nncf->-r requirements.txt (line 12)) (3.0.4)\n",
      "Requirement already satisfied: pymoo>=0.6.0.1 in /home/ubuntu/.venv/lib/python3.12/site-packages (from nncf->-r requirements.txt (line 12)) (0.6.1.5)\n",
      "Requirement already satisfied: rich>=13.5.2 in /home/ubuntu/.venv/lib/python3.12/site-packages (from nncf->-r requirements.txt (line 12)) (14.0.0)\n",
      "Requirement already satisfied: scikit-learn>=0.24.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from nncf->-r requirements.txt (line 12)) (1.7.1)\n",
      "Requirement already satisfied: tabulate>=0.9.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from nncf->-r requirements.txt (line 12)) (0.9.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from datasets>=1.4.0->optimum-intel==1.24.0->-r requirements.txt (line 10)) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from datasets>=1.4.0->optimum-intel==1.24.0->-r requirements.txt (line 10)) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /home/ubuntu/.venv/lib/python3.12/site-packages (from datasets>=1.4.0->optimum-intel==1.24.0->-r requirements.txt (line 10)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/ubuntu/.venv/lib/python3.12/site-packages (from datasets>=1.4.0->optimum-intel==1.24.0->-r requirements.txt (line 10)) (0.70.16)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from jsonschema>=3.2.0->nncf->-r requirements.txt (line 12)) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ubuntu/.venv/lib/python3.12/site-packages (from jsonschema>=3.2.0->nncf->-r requirements.txt (line 12)) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ubuntu/.venv/lib/python3.12/site-packages (from jsonschema>=3.2.0->nncf->-r requirements.txt (line 12)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ubuntu/.venv/lib/python3.12/site-packages (from jsonschema>=3.2.0->nncf->-r requirements.txt (line 12)) (0.26.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ubuntu/.venv/lib/python3.12/site-packages (from pandas<2.3,>=1.1.5->nncf->-r requirements.txt (line 12)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/.venv/lib/python3.12/site-packages (from pandas<2.3,>=1.1.5->nncf->-r requirements.txt (line 12)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ubuntu/.venv/lib/python3.12/site-packages (from pandas<2.3,>=1.1.5->nncf->-r requirements.txt (line 12)) (2025.2)\n",
      "Requirement already satisfied: pyparsing>=3.0.9 in /home/ubuntu/.venv/lib/python3.12/site-packages (from pydot<=3.0.4,>=1.4.1->nncf->-r requirements.txt (line 12)) (3.2.3)\n",
      "Requirement already satisfied: matplotlib>=3 in /home/ubuntu/.venv/lib/python3.12/site-packages (from pymoo>=0.6.0.1->nncf->-r requirements.txt (line 12)) (3.10.3)\n",
      "Requirement already satisfied: autograd>=1.4 in /home/ubuntu/.venv/lib/python3.12/site-packages (from pymoo>=0.6.0.1->nncf->-r requirements.txt (line 12)) (1.8.0)\n",
      "Requirement already satisfied: cma>=3.2.2 in /home/ubuntu/.venv/lib/python3.12/site-packages (from pymoo>=0.6.0.1->nncf->-r requirements.txt (line 12)) (4.3.0)\n",
      "Requirement already satisfied: alive-progress in /home/ubuntu/.venv/lib/python3.12/site-packages (from pymoo>=0.6.0.1->nncf->-r requirements.txt (line 12)) (3.3.0)\n",
      "Requirement already satisfied: Deprecated in /home/ubuntu/.venv/lib/python3.12/site-packages (from pymoo>=0.6.0.1->nncf->-r requirements.txt (line 12)) (1.2.18)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ubuntu/.venv/lib/python3.12/site-packages (from requests->transformers==4.52.4->-r requirements.txt (line 5)) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/.venv/lib/python3.12/site-packages (from requests->transformers==4.52.4->-r requirements.txt (line 5)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.venv/lib/python3.12/site-packages (from requests->transformers==4.52.4->-r requirements.txt (line 5)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/.venv/lib/python3.12/site-packages (from requests->transformers==4.52.4->-r requirements.txt (line 5)) (2025.7.14)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from rich>=13.5.2->nncf->-r requirements.txt (line 12)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from rich>=13.5.2->nncf->-r requirements.txt (line 12)) (2.19.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from scikit-learn>=0.24.0->nncf->-r requirements.txt (line 12)) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from scikit-learn>=0.24.0->nncf->-r requirements.txt (line 12)) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch==2.7.1->-r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from jinja2->torch==2.7.1->-r requirements.txt (line 6)) (3.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/ubuntu/.venv/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.4.0->optimum-intel==1.24.0->-r requirements.txt (line 10)) (3.12.14)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ubuntu/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=13.5.2->nncf->-r requirements.txt (line 12)) (0.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ubuntu/.venv/lib/python3.12/site-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf->-r requirements.txt (line 12)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ubuntu/.venv/lib/python3.12/site-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf->-r requirements.txt (line 12)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf->-r requirements.txt (line 12)) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ubuntu/.venv/lib/python3.12/site-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf->-r requirements.txt (line 12)) (1.4.8)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<2.3,>=1.1.5->nncf->-r requirements.txt (line 12)) (1.17.0)\n",
      "Requirement already satisfied: about-time==4.2.1 in /home/ubuntu/.venv/lib/python3.12/site-packages (from alive-progress->pymoo>=0.6.0.1->nncf->-r requirements.txt (line 12)) (4.2.1)\n",
      "Requirement already satisfied: graphemeu==0.7.2 in /home/ubuntu/.venv/lib/python3.12/site-packages (from alive-progress->pymoo>=0.6.0.1->nncf->-r requirements.txt (line 12)) (0.7.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/ubuntu/.venv/lib/python3.12/site-packages (from Deprecated->pymoo>=0.6.0.1->nncf->-r requirements.txt (line 12)) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.4.0->optimum-intel==1.24.0->-r requirements.txt (line 10)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.4.0->optimum-intel==1.24.0->-r requirements.txt (line 10)) (1.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ubuntu/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.4.0->optimum-intel==1.24.0->-r requirements.txt (line 10)) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ubuntu/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.4.0->optimum-intel==1.24.0->-r requirements.txt (line 10)) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.4.0->optimum-intel==1.24.0->-r requirements.txt (line 10)) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ubuntu/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.4.0->optimum-intel==1.24.0->-r requirements.txt (line 10)) (1.20.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7b1565c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 3 files: 100%|██████████| 3/3 [00:34<00:00, 11.58s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00, 26.03it/s]\n",
      "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "/home/ubuntu/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:556: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  or not self.key_cache[layer_idx].numel()  # the layer has no cache\n",
      "/home/ubuntu/.venv/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:589: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if sequence_length != 1:\n",
      "/home/ubuntu/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:540: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  not self.key_cache[layer_idx].numel()  # prefers not t.numel() to len(t) == 0 to export the model\n",
      "/home/ubuntu/.venv/lib/python3.12/site-packages/transformers/integrations/sdpa_attention.py:47: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  is_causal = query.shape[2] > 1 and causal_mask is None\n",
      "/home/ubuntu/.venv/lib/python3.12/site-packages/transformers/models/clip/modeling_clip.py:219: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if not interpolate_pos_encoding and (height != self.image_size or width != self.image_size):\n",
      "/home/ubuntu/.venv/lib/python3.12/site-packages/transformers/models/llava_next_video/modeling_llava_next_video.py:154: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  ori_width = int(math.sqrt(image_features.shape[1] * self.image_size // self.image_size))\n",
      "The model will be converted with no weights quantization. Quantization of the weights to int8 requires nncf. Please install it with `pip install nncf`\n"
     ]
    }
   ],
   "source": [
    "# Save model to OpenVINO format\n",
    "\n",
    "from optimum.intel.openvino import OVModelForVisualCausalLM\n",
    "\n",
    "# First time: export and save\n",
    "model = OVModelForVisualCausalLM.from_pretrained(\n",
    "    \"llava-hf/LLaVA-NeXT-Video-7B-hf\", \n",
    "    export=True,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "model.save_pretrained(\"./llava_openvino_model\")\n",
    "\n",
    "# Future times: load from local saved version (much faster)\n",
    "model = OVModelForVisualCausalLM.from_pretrained(\"./llava_openvino_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a74a9c",
   "metadata": {},
   "source": [
    "# Upload OV model to HF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42ede3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model card created: README.md\n"
     ]
    }
   ],
   "source": [
    "# Create model card and upload to Hugging Face Hub\n",
    "\n",
    "from huggingface_hub import HfApi, create_repo\n",
    "import os\n",
    "\n",
    "# Replace with your desired repo name\n",
    "REPO_NAME = \"llava-next-video-openvino\"  # Change this to your preferred name\n",
    "HF_USERNAME = \"ezelanza\"  # Replace with your HF username\n",
    "\n",
    "# Create model card content\n",
    "model_card = \"\"\"---\n",
    "license: apache-2.0\n",
    "base_model: llava-hf/LLaVA-NeXT-Video-7B-hf\n",
    "tags:\n",
    "- openvino\n",
    "- llava\n",
    "- multimodal\n",
    "- video\n",
    "- visual-question-answering\n",
    "---\n",
    "\n",
    "# LLaVA-NeXT-Video OpenVINO Model\n",
    "\n",
    "This is an OpenVINO optimized version of the LLaVA-NeXT-Video-7B-hf model.\n",
    "\n",
    "## Model Description\n",
    "- **Base Model**: llava-hf/LLaVA-NeXT-Video-7B-hf\n",
    "- **Optimization**: Converted to OpenVINO format for efficient inference\n",
    "- **Size**: ~7B parameters\n",
    "\n",
    "## Usage\n",
    "\n",
    "```python\n",
    "from optimum.intel.openvino import OVModelForVisualCausalLM\n",
    "\n",
    "model = OVModelForVisualCausalLM.from_pretrained(\"YOUR_USERNAME/llava-next-video-openvino\")\n",
    "```\n",
    "\n",
    "## License\n",
    "This model inherits the license from the original LLaVA-NeXT model.\n",
    "\"\"\"\n",
    "\n",
    "# Save model card\n",
    "with open(\"README.md\", \"w\") as f:\n",
    "    f.write(model_card)\n",
    "\n",
    "print(\"Model card created: README.md\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d419ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to: https://huggingface.co/settings/tokens\n",
      "Create a new token with WRITE permissions\n",
      "\n",
      "Repository created/exists: https://huggingface.co/ezelanza/llava-next-video-openvino\n",
      "Uploading model files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "openvino_language_model.bin:   0%|          | 0.00/26.2G [00:00<?, ?B/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "openvino_vision_resampler_model.bin: 100%|██████████| 100/100 [00:00<00:00, 1.85kB/s]\n",
      "openvino_language_model.bin:   0%|          | 9.37M/26.2G [00:00<04:39, 93.6MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_language_model.bin:   0%|          | 26.2M/26.2G [00:00<12:48, 34.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_language_model.bin:   0%|          | 52.4M/26.2G [00:01<07:52, 55.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_language_model.bin:   0%|          | 78.5M/26.2G [00:01<06:22, 68.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_multi_modal_projector_model.bin: 100%|██████████| 83.9M/83.9M [00:01<00:00, 57.0MB/s]\n",
      "\n",
      "\n",
      "openvino_language_model.bin:   0%|          | 105M/26.2G [00:01<05:46, 75.3MB/s] \n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_language_model.bin:   1%|          | 131M/26.2G [00:01<05:46, 75.0MB/s]\n",
      "\n",
      "openvino_language_model.bin:   1%|          | 155M/26.2G [00:02<04:32, 95.6MB/s]\n",
      "\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   1%|          | 168M/26.2G [00:02<05:25, 79.9MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_language_model.bin:   1%|          | 183M/26.2G [00:02<07:04, 61.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   1%|          | 209M/26.2G [00:03<06:11, 69.9MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_language_model.bin:   1%|          | 236M/26.2G [00:03<06:44, 64.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   1%|          | 262M/26.2G [00:03<06:12, 69.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_language_model.bin:   1%|          | 288M/26.2G [00:04<06:20, 68.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   1%|          | 313M/26.2G [00:04<04:54, 87.7MB/s]\n",
      "\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   1%|          | 326M/26.2G [00:04<06:06, 70.4MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_language_model.bin:   1%|▏         | 340M/26.2G [00:04<07:02, 61.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_language_model.bin:   1%|▏         | 366M/26.2G [00:05<07:44, 55.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_language_model.bin:   2%|▏         | 393M/26.2G [00:05<07:09, 60.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_language_model.bin:   2%|▏         | 419M/26.2G [00:06<06:59, 61.4MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   2%|▏         | 445M/26.2G [00:06<07:14, 59.2MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   2%|▏         | 471M/26.2G [00:07<07:04, 60.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "openvino_language_model.bin:   2%|▏         | 519M/26.2G [00:07<05:09, 83.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   2%|▏         | 531M/26.2G [00:08<07:20, 58.2MB/s]\n",
      "\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   2%|▏         | 550M/26.2G [00:08<07:01, 60.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "openvino_text_embeddings_model.bin: 100%|██████████| 525M/525M [00:08<00:00, 59.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   3%|▎         | 707M/26.2G [00:11<06:20, 66.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   3%|▎         | 733M/26.2G [00:11<08:01, 52.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   3%|▎         | 759M/26.2G [00:12<07:33, 56.1MB/s]\n",
      "\n",
      "openvino_language_model.bin:   3%|▎         | 785M/26.2G [00:12<07:00, 60.3MB/s]\n",
      "\n",
      "openvino_language_model.bin:   3%|▎         | 811M/26.2G [00:12<06:42, 63.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   3%|▎         | 864M/26.2G [00:14<07:57, 53.0MB/s]\n",
      "\n",
      "openvino_language_model.bin:   3%|▎         | 898M/26.2G [00:14<06:26, 65.3MB/s]\n",
      "\n",
      "openvino_language_model.bin:   4%|▎         | 916M/26.2G [00:14<06:28, 65.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   4%|▎         | 968M/26.2G [00:15<05:22, 78.1MB/s]\n",
      "\n",
      "openvino_language_model.bin:   4%|▍         | 994M/26.2G [00:15<04:09, 101MB/s] \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   4%|▍         | 1.01G/26.2G [00:16<06:49, 61.4MB/s]\n",
      "\n",
      "openvino_language_model.bin:   4%|▍         | 1.02G/26.2G [00:16<07:09, 58.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   4%|▍         | 1.05G/26.2G [00:16<06:32, 64.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   4%|▍         | 1.07G/26.2G [00:17<07:56, 52.7MB/s]\n",
      "\n",
      "openvino_language_model.bin:   4%|▍         | 1.10G/26.2G [00:17<07:24, 56.3MB/s]\n",
      "\n",
      "openvino_language_model.bin:   4%|▍         | 1.12G/26.2G [00:17<05:51, 71.3MB/s]\n",
      "\n",
      "openvino_language_model.bin:   4%|▍         | 1.13G/26.2G [00:17<06:07, 68.1MB/s]\n",
      "\n",
      "openvino_language_model.bin:   4%|▍         | 1.15G/26.2G [00:18<06:30, 64.1MB/s]\n",
      "\n",
      "openvino_language_model.bin:   5%|▍         | 1.18G/26.2G [00:18<05:47, 71.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   5%|▍         | 1.20G/26.2G [00:19<06:02, 68.8MB/s]\n",
      "\n",
      "openvino_language_model.bin:   5%|▍         | 1.23G/26.2G [00:19<05:33, 74.7MB/s]\n",
      "\n",
      "openvino_language_model.bin:   5%|▍         | 1.27G/26.2G [00:19<04:46, 86.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "openvino_language_model.bin:   5%|▍         | 1.29G/26.2G [00:20<06:51, 60.4MB/s]\n",
      "\n",
      "openvino_vision_embeddings_model.bin: 100%|██████████| 1.16G/1.16G [00:20<00:00, 56.8MB/s]\n",
      "openvino_language_model.bin: 100%|██████████| 26.2G/26.2G [07:28<00:00, 58.3MB/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Upload 5 LFS files: 100%|██████████| 5/5 [07:29<00:00, 89.82s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model uploaded successfully!\n",
      "🔗 View your model at: https://huggingface.co/ezelanza/ezelanza/llava-next-video-openvino\n"
     ]
    }
   ],
   "source": [
    "# Upload model to Hugging Face Hub\n",
    "\n",
    "from huggingface_hub import HfApi\n",
    "import os\n",
    "# Login to Hugging Face\n",
    "\n",
    "from huggingface_hub import login\n",
    "import getpass\n",
    "\n",
    "print(\"Go to: https://huggingface.co/settings/tokens\")\n",
    "print(\"Create a new token with WRITE permissions\")\n",
    "print()\n",
    "\n",
    "token = getpass.getpass(\"Enter your HF token: \")\n",
    "login(token=token)\n",
    "\n",
    "# Configuration - UPDATE THESE VALUES\n",
    "REPO_NAME = \"ezelanza/llava-next-video-openvino\"  # Your desired repo name\n",
    "# The username will be automatically detected from your login\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "# Create repository\n",
    "try:\n",
    "    repo_url = api.create_repo(\n",
    "        repo_id=REPO_NAME,\n",
    "        exist_ok=True,\n",
    "        repo_type=\"model\"\n",
    "    )\n",
    "    print(f\"Repository created/exists: {repo_url}\")\n",
    "except Exception as e:\n",
    "    print(f\"Repository creation error: {e}\")\n",
    "\n",
    "# Upload model files if they exist\n",
    "if os.path.exists(\"./llava_openvino_model\"):\n",
    "    print(\"Uploading model files...\")\n",
    "    api.upload_folder(\n",
    "        folder_path=\"./llava_openvino_model\",\n",
    "        repo_id=REPO_NAME,\n",
    "        repo_type=\"model\"\n",
    "    )\n",
    "    \n",
    "    # Upload README\n",
    "    if os.path.exists(\"README.md\"):\n",
    "        api.upload_file(\n",
    "            path_or_fileobj=\"README.md\",\n",
    "            path_in_repo=\"README.md\",\n",
    "            repo_id=REPO_NAME,\n",
    "            repo_type=\"model\"\n",
    "        )\n",
    "    \n",
    "    print(f\"✅ Model uploaded successfully!\")\n",
    "    print(f\"🔗 View your model at: https://huggingface.co/{api.whoami()['name']}/{REPO_NAME}\")\n",
    "else:\n",
    "    print(\"❌ Model directory './llava_openvino_model' not found.\")\n",
    "    print(\"Run the first cell to save the model first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbf6f8f",
   "metadata": {},
   "source": [
    "# Load the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c84aca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"ezelanza/llava-next-video-openvino\"\n",
    "from transformers import LlavaNextVideoProcessor\n",
    "\n",
    "model = OVModelForVisualCausalLM.from_pretrained(model_id)\n",
    "processor = LlavaNextVideoProcessor.from_pretrained(\"llava-hf/LLaVA-NeXT-Video-7B-hf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0758349",
   "metadata": {},
   "source": [
    "# Optimize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "438a6d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from optimum.intel import OVQuantizationConfig, OVWeightQuantizationConfig, OVPipelineQuantizationConfig\n",
    "\n",
    "dataset, num_samples = \"contextual\", 50\n",
    "\n",
    "# weight-only 8bit\n",
    "woq_8bit = OVWeightQuantizationConfig(bits=8)\n",
    "\n",
    "# weight-only 4bit\n",
    "woq_4bit = OVWeightQuantizationConfig(bits=4, group_size=16)\n",
    "\n",
    "# static quantization\n",
    "static_8bit = OVQuantizationConfig(bits=8, dataset=dataset, num_samples=num_samples)\n",
    "\n",
    "# pipeline quantization: applying different quantization on each components\n",
    "ppl_q = OVPipelineQuantizationConfig(\n",
    "    quantization_configs={\n",
    "        \"lm_model\": OVQuantizationConfig(bits=8),\n",
    "        \"multimodal_model\": OVWeightQuantizationConfig(bits=8),\n",
    "        \"text_embeddings_model\": OVWeightQuantizationConfig(bits=8),\n",
    "        \"vision_embeddings_model\": OVWeightQuantizationConfig(bits=8),\n",
    "        \"vision_model\": OVWeightQuantizationConfig(bits=8) \n",
    "    },\n",
    "    dataset=dataset,\n",
    "    num_samples=num_samples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42edb4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:Statistics of the bitwidth distribution:\n",
      "┍━━━━━━━━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┑\n",
      "│ Weight compression mode   │ % all parameters (layers)   │ % ratio-defining parameters (layers)   │\n",
      "┝━━━━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┥\n",
      "│ int8_asym                 │ 100% (225 / 225)            │ 100% (225 / 225)                       │\n",
      "┕━━━━━━━━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┙\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/ubuntu/.venv/lib/python3.12/site-packages/rich/live.py:231: UserWarning: install \"ipywidgets\" for Jupyter \n",
       "support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/ubuntu/.venv/lib/python3.12/site-packages/rich/live.py:231: UserWarning: install \"ipywidgets\" for Jupyter \n",
       "support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:Statistics of the bitwidth distribution:\n",
      "┍━━━━━━━━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┑\n",
      "│ Weight compression mode   │ % all parameters (layers)   │ % ratio-defining parameters (layers)   │\n",
      "┝━━━━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┥\n",
      "│ int8_sym                  │ 100% (1 / 1)                │ 100% (1 / 1)                           │\n",
      "┕━━━━━━━━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┙\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:Statistics of the bitwidth distribution:\n",
      "┍━━━━━━━━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┑\n",
      "│ Weight compression mode   │ % all parameters (layers)   │ % ratio-defining parameters (layers)   │\n",
      "┝━━━━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┥\n",
      "│ int8_sym                  │ 100% (139 / 139)            │ 100% (139 / 139)                       │\n",
      "┕━━━━━━━━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┙\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:Statistics of the bitwidth distribution:\n",
      "┍━━━━━━━━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┑\n",
      "│ Weight compression mode   │ % all parameters (layers)   │ % ratio-defining parameters (layers)   │\n",
      "┝━━━━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┥\n",
      "┕━━━━━━━━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┙\n",
      "INFO:nncf:Statistics of the bitwidth distribution:\n",
      "┍━━━━━━━━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┑\n",
      "│ Weight compression mode   │ % all parameters (layers)   │ % ratio-defining parameters (layers)   │\n",
      "┝━━━━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┥\n",
      "│ int8_sym                  │ 100% (2 / 2)                │ 100% (2 / 2)                           │\n",
      "┕━━━━━━━━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┙\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from optimum.intel import OVModelForVisualCausalLM, OVWeightQuantizationConfig\n",
    "\n",
    "model_id = \"ezelanza/llava-next-video-openvino\"\n",
    "\n",
    "q_model = OVModelForVisualCausalLM.from_pretrained(model_id, quantization_config=woq_8bit)\n",
    "int8_model_path = \"llava_next_video_int8\"\n",
    "q_model.save_pretrained(int8_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0a662c",
   "metadata": {},
   "source": [
    "# Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8436ca96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused or unrecognized kwargs: return_tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: \n",
      "What is happening in the video? ASSISTANT: In the video, we see a young child sitting on a bed, wearing glasses and holding a book. The child appears to be engaged in reading or looking at the book, possibly turning the pages. The room has a cozy and lived-in feel, with various items like a bed\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download \n",
    "from transformers import LlavaNextVideoProcessor\n",
    "from optimum.intel.openvino import OVModelForVisualCausalLM\n",
    "\n",
    "video_path = hf_hub_download(repo_id=\"raushan-testing-hf/videos-test\", filename=\"sample_demo_1.mp4\", repo_type=\"dataset\")\n",
    "\n",
    "conversation = [\n",
    "    {\n",
    "\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"What is happening in the video?\"},\n",
    "            {\"type\": \"video\", \"path\": video_path},\n",
    "            ],\n",
    "    },\n",
    "]\n",
    "processor = LlavaNextVideoProcessor.from_pretrained(\"llava-hf/LLaVA-NeXT-Video-7B-hf\")\n",
    "model = OVModelForVisualCausalLM.from_pretrained(\"./llava_next_video_int8\")\n",
    "\n",
    "\n",
    "inputs = processor.apply_chat_template(\n",
    "    conversation,\n",
    "    num_frames=8,\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=True,\n",
    "    return_dict=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# 🚀 Step 5: Run inference\n",
    "out = model.generate(**inputs, max_new_tokens=60)\n",
    "\n",
    "# 🧾 Step 6: Decode output\n",
    "response = processor.batch_decode(\n",
    "    out,\n",
    "    skip_special_tokens=True,\n",
    "    clean_up_tokenization_spaces=True\n",
    ")[0]\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
